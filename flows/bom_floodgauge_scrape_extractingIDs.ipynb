{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-15 08:18:18] INFO: Fetched (200) <GET http://www.bom.gov.au/cgi-bin/wrap_fwo.pl?IDQ60005.html> (referer: https://www.google.com/search?q=bom)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scrapling.engines.toolbelt.custom.Response'>\n"
     ]
    }
   ],
   "source": [
    "from scrapling import Fetcher\n",
    "page = Fetcher().get('http://www.bom.gov.au/cgi-bin/wrap_fwo.pl?IDQ60005.html', stealthy_headers=True, follow_redirects=True)\n",
    "\n",
    "#print the type of the page\n",
    "print(type(page))\n",
    "\n",
    "#convert page to string\n",
    "page = str(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Station Name    Time/Day  Height Tendency  \\\n",
      "0     Lt Nerang Ck at Little Nerang Dam *  6.30am Wed  168.17   steady   \n",
      "1     Lt Nerang Ck at Little Nerang Dam #  5.46am Wed    0.16   steady   \n",
      "2           Nerang R at Numinbah Valley *  7.00am Wed    0.96   steady   \n",
      "3           Nerang R at Numinbah Valley #  5.41am Wed    0.95   steady   \n",
      "4                 Nerang R at Hinze Dam *  6.00am Wed   95.09   steady   \n",
      "...                                   ...         ...     ...      ...   \n",
      "1267                   Ugar Island Tide *  7.29am Wed    1.34   rising   \n",
      "1268                   Iama Island Tide *  7.34am Wed    0.75   steady   \n",
      "1269         Moa Island (St Pauls) Tide *  7.30am Wed    0.94   steady   \n",
      "1270            Moa Island (Kubin) Tide *  7.32am Wed    2.40   steady   \n",
      "1271               Thursday Island Tide *  7.35am Wed    1.66   steady   \n",
      "\n",
      "                 Crossing  Flood Class Recent Data      None    None  \n",
      "0     0.15 above Spillway               Plot|Table  IDQ65388  540612  \n",
      "1     0.16 above Spillway  below minor  Plot|Table  IDQ65388  540054  \n",
      "2                                       Plot|Table  IDQ65388  540437  \n",
      "3                                       Plot|Table  IDQ65388  540438  \n",
      "4     0.59 above Spillway  below minor  Plot|Table  IDQ65388  540610  \n",
      "...                   ...          ...         ...       ...     ...  \n",
      "1267       2.77 below HAT               Plot|Table  IDQ65399  527022  \n",
      "1268       3.41 below HAT               Plot|Table  IDQ65399  527018  \n",
      "1269       3.19 below HAT               Plot|Table  IDQ65399  527021  \n",
      "1270       1.37 below HAT               Plot|Table  IDQ65399  527017  \n",
      "1271       2.20 below HAT               Plot|Table  IDQ65399  527005  \n",
      "\n",
      "[1272 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#convert page to string\n",
    "page_str = str(page)\n",
    "\n",
    "page_soup = BeautifulSoup(page_str, \"html.parser\")\n",
    "\n",
    "# Find the table (assuming there's only one table in the HTML)\n",
    "table = page_soup.find(\"table\")\n",
    "\n",
    "all_rows = []  # will hold lists of cell values\n",
    "\n",
    "for tr in table.find_all(\"tr\"):\n",
    "    # Gather all cells (td/th) in this row\n",
    "    cells = tr.find_all([\"td\", \"th\"])\n",
    "    \n",
    "    # Skip row if any cell has a colspan\n",
    "    # (You could also check for rowspan if needed)\n",
    "    skip_row = any(cell.has_attr(\"colspan\") for cell in cells)\n",
    "    if skip_row:\n",
    "        continue\n",
    "\n",
    "    # Extract the text from each cell in the row\n",
    "    row_data = [cell.get_text(strip=True) for cell in cells]\n",
    "    \n",
    "    # You mention the table has 7 columns, so only keep rows that have 7 cells\n",
    "    if len(row_data) == 7:\n",
    "        all_rows.append(row_data)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Look for the link that contains the word \"plot\" (case-insensitive)\n",
    "    # -------------------------------------------------------------------------\n",
    "    plot_link_tag = tr.find(\"a\", string=lambda text: text and \"plot\" in text.lower())\n",
    "    \n",
    "    # If found, parse the link's href to extract your IDQ number and second number\n",
    "    if plot_link_tag and plot_link_tag.has_attr(\"href\"):\n",
    "        href = plot_link_tag[\"href\"]  # e.g. http://www.bom.gov.au/fwo/IDQ65388/IDQ65388.540612.plt.shtml\n",
    "        \n",
    "        # Get the filename after the last slash, e.g. \"IDQ65388.540612.plt.shtml\"\n",
    "        filename = href.split(\"/\")[-1]\n",
    "        \n",
    "        # Use a regular expression to capture the part before the first '.' and the next part\n",
    "        # Pattern: ^(.*?)\\.(.*?)\\.plt\\.shtml$\n",
    "        match = re.match(r'^(.*?)\\.(.*?)\\.plt\\.shtml$', filename)\n",
    "        if match:\n",
    "            idq_number = match.group(1)     # e.g. \"IDQ65388\"\n",
    "            second_number = match.group(2)  # e.g. \"540612\"\n",
    "        else:\n",
    "            idq_number = None\n",
    "            second_number = None\n",
    "    else:\n",
    "        # If there is no link or no href attribute\n",
    "        idq_number = None\n",
    "        second_number = None\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Append these two new values into row_data\n",
    "    # -------------------------------------------------------------------------\n",
    "    row_data.append(idq_number)\n",
    "    row_data.append(second_number)\n",
    "    \n",
    "    #all_rows.append(row_data)\n",
    "\n",
    "# Now `all_rows` has 7 + 2 = 9 columns total:\n",
    "#   original 7 columns + IDQ_number + second_number\n",
    "\n",
    "# If the first row in `all_rows` is your header, then:\n",
    "header = all_rows[0]  # e.g. the original 7 column headers (if that's truly a header row)\n",
    "# You might want to adjust for the new columns in the header, for example:\n",
    "header = header + [\"IDQ_Number\", \"Second_Number\"]\n",
    "\n",
    "# Assuming the first row is the header\n",
    "df = pd.DataFrame(all_rows[1:], columns=all_rows[0])\n",
    "# df = pd.DataFrame(all_rows[1:], columns=header)\n",
    "\n",
    "# remove any instances of \"^\" from the height column\n",
    "df['Height'] = df['Height'].str.replace('^', '')\n",
    "\n",
    "# convert height column to float\n",
    "# df['Height'] = df['Height'].astype(float)\n",
    "\n",
    "print(df)\n",
    "\n",
    "#export to csv\n",
    "df.to_csv('flood.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
